# ComfyUI-SAM4DBodyCapture

**Temporally Consistent 4D Human Mesh Recovery from Videos**

A ComfyUI package integrating SAM-Body4D and Diffusion-VAS for robust human body capture with camera and character export capabilities.

[![Version](https://img.shields.io/badge/version-0.1.0-blue.svg)](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/releases)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## üéØ Features

### Current (v0.1.0)
- üé≠ **Diffusion-VAS Integration** - Video Amodal Segmentation
  - Recover complete object masks even when heavily occluded
  - Inpaint occluded regions using diffusion priors
  - Depth-conditioned temporal modeling

### Planned
- üèÇ **SAM-Body4D** (v0.2.0) - Temporally consistent mesh recovery
- üì¶ **Export Nodes** (v0.3.0) - FBX/Alembic for character and camera
- üé• **Camera Integration** (v0.4.0) - Integration with SAM3DBody2abc camera solver

## üì¶ Installation

### From GitHub (Recommended)
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/llikethat/ComfyUI-SAM4DBodyCapture.git
cd ComfyUI-SAM4DBodyCapture
pip install -r requirements.txt
```

### Model Downloads
Models are automatically downloaded from HuggingFace on first use:

| Model | Size | Purpose |
|-------|------|---------|
| diffusion-vas-amodal-segmentation | ~2GB | Amodal mask generation |
| diffusion-vas-content-completion | ~2GB | Occluded region inpainting |
| Depth-Anything-V2-Large | ~700MB | Pseudo-depth estimation |

## üîß Nodes

### Diffusion-VAS Nodes

#### üé≠ Load Diffusion-VAS Models
Load all required models for amodal segmentation.

| Parameter | Description |
|-----------|-------------|
| depth_model | Depth Anything V2 variant (Large/Base/Small) |
| device | cuda, cpu, or auto |
| dtype | float16, bfloat16, or float32 |

#### üé≠ Amodal Segmentation
Generate complete object masks from partial/occluded views.

| Input | Type | Description |
|-------|------|-------------|
| vas_model | DIFFUSION_VAS_MODEL | From loader node |
| images | IMAGE | Video frames |
| modal_masks | MASK | Visible masks from SAM3 |

| Output | Type | Description |
|--------|------|-------------|
| amodal_masks | MASK | Complete object masks |
| depth_maps | IMAGE | Pseudo-depth visualization |

#### üé≠ Content Completion
Inpaint occluded regions of objects.

| Input | Type | Description |
|-------|------|-------------|
| vas_model | DIFFUSION_VAS_MODEL | From loader node |
| images | IMAGE | Video frames |
| modal_masks | MASK | Visible masks |
| amodal_masks | MASK | Complete masks |

| Output | Type | Description |
|--------|------|-------------|
| completed_content | IMAGE | Frames with inpainted regions |

## üîÑ Workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load Video  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    SAM 3     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Diffusion-VAS     ‚îÇ
‚îÇ             ‚îÇ     ‚îÇ (Segmentation)‚îÇ     ‚îÇ (Amodal + Complete)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ SAM 3D Body  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Export FBX/ABC    ‚îÇ
                    ‚îÇ (Per-frame)  ‚îÇ     ‚îÇ (Character+Camera) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üíª Requirements

### Hardware
- **Minimum**: NVIDIA GPU with 12GB VRAM
- **Recommended**: 16-24GB VRAM
- CPU mode available but slow

### Software
- Python 3.10+
- CUDA 11.8+ (for GPU acceleration)
- ComfyUI (latest)

## üìú License

This project is licensed under MIT.

### Third-Party Licenses
| Component | License | Commercial Use |
|-----------|---------|----------------|
| SAM-Body4D | MIT | ‚úÖ Allowed |
| Diffusion-VAS | MIT | ‚úÖ Allowed |
| SAM 3D Body | SAM License | ‚ö†Ô∏è Restricted (no military/nuclear) |
| Stable Video Diffusion | Stability AI | ‚ö†Ô∏è Check for >$1M revenue |
| Depth Anything V2 | Apache 2.0 | ‚úÖ Allowed |

## üôè Acknowledgments

This project builds upon:
- [SAM-Body4D](https://github.com/gaomingqi/sam-body4d) by Mingqi Gao et al.
- [Diffusion-VAS](https://github.com/Kaihua-Chen/diffusion-vas) by Kaihua Chen et al.
- [SAM 3D Body](https://github.com/facebookresearch/sam-3d-body) by Meta AI

## üìö Citations

If you use this work, please cite:

```bibtex
@article{gao2025sambody4d,
    title={SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos},
    author={Gao, Mingqi and Miao, Yunqi and Han, Jungong},
    journal={arXiv preprint arXiv:2512.08406},
    year={2025}
}

@inproceedings{chen2025diffvas,
    title={Using Diffusion Priors for Video Amodal Segmentation},
    author={Chen, Kaihua and Ramanan, Deva and Khurana, Tarasha},
    booktitle={CVPR},
    year={2025}
}
```

## üó∫Ô∏è Roadmap

- [x] v0.1.0 - Diffusion-VAS nodes (skeleton)
- [ ] v0.1.1 - Complete Diffusion-VAS implementation
- [ ] v0.2.0 - SAM-Body4D integration
- [ ] v0.3.0 - FBX/Alembic export
- [ ] v0.4.0 - Camera solver integration
- [ ] v1.0.0 - First stable release

## ü§ù Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) first.

## üìû Support

- Issues: [GitHub Issues](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/issues)
- Discussions: [GitHub Discussions](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/discussions)
