# ComfyUI-SAM4DBodyCapture

**Temporally Consistent 4D Human Mesh Recovery from Videos**

A ComfyUI package integrating SAM-Body4D and Diffusion-VAS for robust human body capture with occlusion handling, temporal smoothing, and mesh export.

[![Version](https://img.shields.io/badge/version-0.3.13-blue.svg)](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/releases)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## üéØ Features

### v0.3.0 - Export Nodes
- üì¶ **FBX Export** - Character meshes for Maya, Blender, Unreal, Unity
- üì¶ **Alembic Export** - Point cache for VFX pipelines
- üì¶ **OBJ Sequence** - Universal per-frame mesh files
- üé• **Camera Export** - FBX and JSON camera animation
- üåê **Coordinate Systems** - Presets for all major 3D software

### v0.2.0 - SAM4D Pipeline
- üé¨ **Complete Pipeline** - One-click occlusion detection and completion
- üîç **Smart Occlusion Detection** - IoU-based identification of hidden body parts  
- üé≠ **Amodal Completion** - Recover complete masks using diffusion priors
- üîÑ **Temporal Fusion** - Smooth mesh sequences with Gaussian/EMA filtering

### Previous Versions
- v0.1.x - Diffusion-VAS standalone nodes

### Planned
- üì¶ **FBX/Alembic Export** (v0.3.0) - Skinned mesh animation export
- üé• **Camera Integration** (v0.4.0) - Integration with camera solver

## üì¶ Installation

```bash
cd ComfyUI/custom_nodes
git clone https://github.com/llikethat/ComfyUI-SAM4DBodyCapture.git
cd ComfyUI-SAM4DBodyCapture
pip install -r requirements.txt
```

### Model Downloads (Automatic)
Models download from HuggingFace on first use:

| Model | Size | Purpose |
|-------|------|---------|
| Depth-Anything-V2-Large | ~700MB | Depth estimation |
| diffusion-vas-amodal-segmentation | ~2GB | Amodal mask prediction |
| diffusion-vas-content-completion | ~2GB | RGB inpainting (optional) |

## üîß Nodes (17 Total)

### SAM4D Pipeline Nodes

| Node | Description |
|------|-------------|
| üé¨ **Load SAM4D Pipeline** | Load all models (depth, amodal, completion) |
| üîç **Detect Occlusions** | Find frames with occluded body parts |
| üé≠ **Complete Occluded Regions** | Fill in missing mask/RGB regions |
| üóëÔ∏è **Unload SAM4D Pipeline** | Free GPU memory |

### Temporal & Mesh Nodes

| Node | Description |
|------|-------------|
| üîÑ **Temporal Fusion** | Smooth vertex/parameter jitter |
| ‚ú® **Create Mesh Sequence** | Build sequence from SAM3DBody `mesh_data` (SAM3D_OUTPUT) |
| üëÅÔ∏è **Visualize Mesh Sequence** | Preview mesh as point cloud |
| üì¶ **Export Mesh Sequence** | NPZ compressed format |

### Export Nodes

| Node | Description |
|------|-------------|
| üì¶ **Export Character FBX** | Animated FBX via Blender (Maya, Blender, Unreal) |
| üì¶ **Export Character Alembic** | Point cache for VFX pipelines |
| üé• **Export Camera FBX** | Camera animation FBX |
| üé• **Export Camera JSON** | Universal camera format |
| üé• **FBX Animation Viewer** | Interactive 3D viewer in ComfyUI |

### Diffusion-VAS Nodes (Standalone)

| Node | Description |
|------|-------------|
| üé≠ **Load Diffusion-VAS Models** | Load VAS models only |
| üé≠ **Amodal Segmentation** | Generate complete masks |
| üé≠ **Content Completion** | Inpaint occluded RGB |
| üé≠ **Unload VAS Models** | Free VAS memory |

## üîÄ Two Loader Options (Fully Compatible)

Both loaders can be used with any downstream node!

### Option 1: SAM4D Pipeline Loader (Recommended)
For full body capture with occlusion handling and temporal processing.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load SAM4D Pipeline ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ (SAM4D_PIPELINE or  ‚îÇ                                      ‚îÇ
‚îÇ  VAS_PIPELINE)      ‚îÇ                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                      ‚îÇ
         ‚îÇ                                                   ‚îÇ
         ‚ñº                                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Detect Occlusions  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Complete Occluded Regions         ‚îÇ
‚îÇ     + depth_maps    ‚îÇ     ‚îÇ   (only processes occluded frames)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
  occlusion_info              completed_masks, completed_images
```

### Option 2: Standalone VAS Loader
For amodal segmentation only (simpler setup).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load Diffusion-VAS      ‚îÇ
‚îÇ (SAM4D_PIPELINE or      ‚îÇ
‚îÇ  VAS_PIPELINE)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Amodal Segmentation    ‚îÇ
‚îÇ     + depth_maps        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    amodal_masks
```

### Compatibility Matrix

| Loader | Can Connect To |
|--------|----------------|
| Load SAM4D Pipeline | ‚úÖ All SAM4D nodes, ‚úÖ All VAS nodes |
| Load Diffusion-VAS | ‚úÖ All SAM4D nodes, ‚úÖ All VAS nodes |

### When to Use Which

| Use Case | Loader |
|----------|--------|
| Full body capture workflow | **SAM4D Pipeline** |
| Just amodal mask generation | Either |
| Testing VAS models | **Diffusion-VAS** |
| Integration with SAM3DBody | **SAM4D Pipeline** |

## üîÑ Workflow

### Complete Pipeline
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SAM4D Pipeline Workflow                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                   ‚îÇ
‚îÇ   Video ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ SAM3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Load SAM4D Pipeline                   ‚îÇ
‚îÇ                  ‚îÇ                  ‚îÇ                             ‚îÇ
‚îÇ                  ‚ñº                  ‚ñº                             ‚îÇ
‚îÇ              Masks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Detect Occlusions                      ‚îÇ
‚îÇ                                ‚îÇ                                  ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚ñº                       ‚ñº                      ‚îÇ
‚îÇ              Occluded?              Not Occluded                 ‚îÇ
‚îÇ                    ‚îÇ                       ‚îÇ                      ‚îÇ
‚îÇ                    ‚ñº                       ‚îÇ                      ‚îÇ
‚îÇ         Complete Occluded ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                     ‚îÇ
‚îÇ                    ‚îÇ                       ‚îÇ                      ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                                ‚ñº                                  ‚îÇ
‚îÇ                          SAM3DBody                               ‚îÇ
‚îÇ                                ‚îÇ                                  ‚îÇ
‚îÇ                                ‚ñº                                  ‚îÇ
‚îÇ                       Temporal Fusion                            ‚îÇ
‚îÇ                                ‚îÇ                                  ‚îÇ
‚îÇ                                ‚ñº                                  ‚îÇ
‚îÇ                      Export Mesh Sequence                        ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Node Details

#### üé¨ Load SAM4D Pipeline
```
Inputs:
‚îú‚îÄ‚îÄ depth_model: Large | Base | Small
‚îú‚îÄ‚îÄ resolution: 512x1024 | 256x512 | 384x768
‚îú‚îÄ‚îÄ enable_amodal: bool (default: True)
‚îú‚îÄ‚îÄ enable_completion: bool (default: False)
‚îú‚îÄ‚îÄ device: cuda | cpu | auto
‚îî‚îÄ‚îÄ dtype: float16 | float32

Output:
‚îî‚îÄ‚îÄ SAM4D_PIPELINE
```

#### üîç Detect Occlusions
```
Inputs:
‚îú‚îÄ‚îÄ pipeline: SAM4D_PIPELINE
‚îú‚îÄ‚îÄ images: IMAGE (video frames)
‚îú‚îÄ‚îÄ masks: MASK (from SAM3)
‚îú‚îÄ‚îÄ iou_threshold: 0.7 (frames below this are occluded)
‚îú‚îÄ‚îÄ object_ids: "1" or "1,2,3" (multi-person)
‚îî‚îÄ‚îÄ num_frames: 25

Outputs:
‚îú‚îÄ‚îÄ occlusion_info: SAM4D_OCCLUSION_INFO
‚îú‚îÄ‚îÄ depth_maps: IMAGE
‚îî‚îÄ‚îÄ amodal_masks: MASK
```

#### üîÑ Temporal Fusion
```
Inputs:
‚îú‚îÄ‚îÄ mesh_sequence: SAM4D_MESH_SEQUENCE
‚îú‚îÄ‚îÄ method: gaussian | ema | none
‚îú‚îÄ‚îÄ smoothing_strength: 1.0 (higher = smoother)
‚îú‚îÄ‚îÄ smooth_vertices: bool
‚îî‚îÄ‚îÄ smooth_params: bool

Output:
‚îî‚îÄ‚îÄ smoothed_sequence: SAM4D_MESH_SEQUENCE
```

## üíª Requirements

### Hardware
| Level | VRAM | Notes |
|-------|------|-------|
| Minimum | 12GB | Depth only, CPU fallback |
| Recommended | 16GB | Full pipeline |
| Optimal | 24GB | All features + high resolution |

### Software
- Python 3.10+
- CUDA 11.8+
- ComfyUI (latest)
- PyTorch 2.0+

## üìú License

MIT License - see [LICENSE](LICENSE)

### Third-Party Components
| Component | License | Notes |
|-----------|---------|-------|
| SAM-Body4D | MIT | ‚úÖ Commercial OK |
| Diffusion-VAS | MIT | ‚úÖ Commercial OK |
| SAM 3D Body | SAM License | ‚ö†Ô∏è No military/nuclear |
| Depth Anything V2 | Apache 2.0 | ‚úÖ Commercial OK |
| SVD (in VAS) | Stability AI | ‚ö†Ô∏è Check if revenue >$1M |

## üó∫Ô∏è Roadmap

- [x] v0.1.0 - Diffusion-VAS skeleton
- [x] v0.1.1 - Diffusion-VAS with depth
- [x] v0.2.0 - SAM4D pipeline integration
- [x] v0.3.0 - FBX/Alembic export
- [x] v0.3.1 - SAM3D_OUTPUT compatibility
- [x] v0.3.2 - Blender FBX export, FBX viewer
- [x] v0.3.3 - External depth input support
- [x] v0.3.4 - Import fixes
- [x] v0.3.5 - Checkpoint manager (auto model downloads)
- [x] v0.3.6 - HuggingFace token support
- [x] v0.3.7 - Pipeline compatibility fixes
- [x] v0.3.8 - Unified pipeline types (SAM4D/VAS interchangeable)
- [x] v0.3.9 - VAS model loading fix (module alias)
- [x] v0.3.10 - VAS module registration fix
- [x] v0.3.11 - Chunked processing for long videos
- [x] v0.3.12 - Fixed num_frames auto-detection (SAM-Body4D approach)
- [x] v0.3.13 - Chunked processing with adjustable chunk_size (OOM fix)
- [ ] v0.4.0 - Remove standalone VAS, camera solver integration  
- [ ] v1.0.0 - Stable release

## üôè Acknowledgments

- [SAM-Body4D](https://github.com/gaomingqi/sam-body4d) - Mingqi Gao et al.
- [Diffusion-VAS](https://github.com/Kaihua-Chen/diffusion-vas) - Kaihua Chen et al.
- [SAM 3D Body](https://github.com/facebookresearch/sam-3d-body) - Meta AI
- [Depth Anything V2](https://github.com/DepthAnything/Depth-Anything-V2)

## üìö Citation

```bibtex
@article{gao2025sambody4d,
    title={SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos},
    author={Gao, Mingqi and others},
    journal={arXiv:2512.08406},
    year={2025}
}

@inproceedings{chen2025diffvas,
    title={Using Diffusion Priors for Video Amodal Segmentation},
    author={Chen, Kaihua and others},
    booktitle={CVPR},
    year={2025}
}
```

## üìû Support

- [Issues](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/issues)
- [Discussions](https://github.com/llikethat/ComfyUI-SAM4DBodyCapture/discussions)
